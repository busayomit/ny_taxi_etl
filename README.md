# NYC Taxi Data Engineering Project

## Overview

Hello Everyone!, this is an ETL I built that focuses on processing and analyzing New York City taxi trip data. The key technologies used include Docker for infrastructure management, Terraform for provisioning, Jupyter Notebook for exploratory data analysis, and a Postgres database for storing and querying the transformed data, all on a GCP Virtual Machine.

## Goal

The primary objective of this project is to demonstrate effective data engineering practices by handling and processing large volumes of NYC taxi trip data. The common goal is to transform raw taxi trip records into a structured format, making it easier to derive meaningful insights and perform analytics.

## Technologies Used

1. **Google Cloud Platform (GCP):**
   - Utilized GCP Virtual Machine for scalable and reliable computing resources.

2. **Docker:**
   - Implemented Docker for containerization, ensuring consistency across different environments and simplifying infrastructure management.

3. **Terraform:**
   - Employed Terraform for infrastructure as code (IaC), streamlining the provisioning of GCP resources and maintaining infrastructure versioning.

4. **Jupyter Notebook:**
   - Leveraged Jupyter Notebook for exploratory data analysis, providing an interactive and collaborative environment for initial data exploration.

5. **ETL Process to Postgres:**
   - Developed an Extract, Transform, Load (ETL) process to extract raw taxi trip data, transform it into a structured format, and load it into a Postgres database.

6. **Postgres Database:**
   - Utilized Postgres for storing the transformed data, enabling efficient querying and analysis.
